# ê²€ìƒ‰ ì„œë¹„ìŠ¤ ëª…ì„¸ì„œ (Search Service Specification)

| í•­ëª© | ë‚´ìš© |
|------|------|
| ë¬¸ì„œ ID | AEG-SPC-20250917-1.0 |
| ë²„ì „ | 1.0 |
| ìµœì¢… ìˆ˜ì •ì¼ | 2025ë…„ 9ì›” 17ì¼ |
| ì‘ì„±ì | Dr. Aiden (ìˆ˜ì„ AI ì‹œìŠ¤í…œ ì•„í‚¤í…íŠ¸) |
| ìƒíƒœ | í™•ì • (Finalized) |

## 1. ì„œë¹„ìŠ¤ ê°œìš” (Service Overview)

ê²€ìƒ‰ ì„œë¹„ìŠ¤ëŠ” ì´ì§€ìŠ¤ ì‹œìŠ¤í…œì˜ ì •ì±… ê²€ìƒ‰ ê¸°ëŠ¥ì„ ë‹´ë‹¹í•˜ëŠ” ì „ë¬¸ ì„œë¹„ìŠ¤ì´ë‹¤. **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„**ì„ í†µí•´ í‚¤ì›Œë“œ ê²€ìƒ‰, ì˜ë¯¸ ê²€ìƒ‰, í•„í„°ë§ ê²€ìƒ‰ì„ í†µí•©í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì •í™•í•˜ê³  ë¹ ë¥¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì œê³µí•œë‹¤.

### 1.1. í•µì‹¬ ì±…ì„ (Core Responsibilities)
- í‚¤ì›Œë“œ ê¸°ë°˜ ì „ë¬¸ ê²€ìƒ‰ (Full-text Search)
- ì˜ë¯¸ ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ (Semantic Search)
- ë‹¤ì¤‘ ì¡°ê±´ í•„í„°ë§ ê²€ìƒ‰
- ê²€ìƒ‰ ê²°ê³¼ ë­í‚¹ ë° ì •ë ¬
- ê²€ìƒ‰ ì„±ëŠ¥ ìµœì í™” ë° ìºì‹±

### 1.2. ì„œë¹„ìŠ¤ ê²½ê³„ (Service Boundaries)
**í¬í•¨í•˜ëŠ” ê¸°ëŠ¥:**
- ì •ì±… ê²€ìƒ‰ ì—”ì§„
- ê²€ìƒ‰ ì¸ë±ìŠ¤ ê´€ë¦¬
- ê²€ìƒ‰ ê²°ê³¼ ìºì‹±
- ê²€ìƒ‰ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

**í¬í•¨í•˜ì§€ ì•ŠëŠ” ê¸°ëŠ¥:**
- ê°œì¸í™” ì¶”ì²œ (Recommendation Service ë‹´ë‹¹)
- ì‚¬ìš©ì ê´€ë¦¬ (User Service ë‹´ë‹¹)
- ì •ì±… ë°ì´í„° ê´€ë¦¬ (Policy Service ë‹´ë‹¹)

## 2. ê²€ìƒ‰ ì•„í‚¤í…ì²˜

### 2.1. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„
```mermaid
graph TB
    subgraph "Search Service"
        A[Search Controller]
        B[Query Parser]
        C[Search Orchestrator]
    end
    
    subgraph "Search Engines"
        D[Elasticsearch<br/>Full-text Search]
        E[Milvus<br/>Vector Search]
        F[PostgreSQL<br/>Filter Search]
    end
    
    subgraph "Result Processing"
        G[Result Merger]
        H[Ranking Engine]
        I[Cache Manager]
    end
    
    A --> B
    B --> C
    C --> D
    C --> E
    C --> F
    D --> G
    E --> G
    F --> G
    G --> H
    H --> I
```

### 2.2. ê²€ìƒ‰ ì „ëµ
| ê²€ìƒ‰ íƒ€ì… | ì—”ì§„ | ìš©ë„ | ê°€ì¤‘ì¹˜ |
|-----------|------|------|--------|
| **í‚¤ì›Œë“œ ê²€ìƒ‰** | Elasticsearch | ì •í™•í•œ ìš©ì–´ ë§¤ì¹­ | 40% |
| **ì˜ë¯¸ ê²€ìƒ‰** | Milvus | ì˜ë¯¸ì  ìœ ì‚¬ì„± | 35% |
| **í•„í„° ê²€ìƒ‰** | PostgreSQL | ì¡°ê±´ë¶€ í•„í„°ë§ | 25% |

## 3. API ëª…ì„¸

### 3.1. í†µí•© ê²€ìƒ‰ API
```http
GET /api/v1/search/policies
```

**Query Parameters:**
```
q: ê²€ìƒ‰ í‚¤ì›Œë“œ (í•„ìˆ˜)
region: ì§€ì—­ í•„í„° (ì„ íƒ)
industry: ì—…ì¢… í•„í„° (ì„ íƒ)
business_type: ì‚¬ì—…ì ìœ í˜• í•„í„° (ì„ íƒ)
funding_type: ìê¸ˆ ìœ í˜• í•„í„° (ì„ íƒ)
amount_min: ìµœì†Œ ì§€ì›ê¸ˆì•¡ (ì„ íƒ)
amount_max: ìµœëŒ€ ì§€ì›ê¸ˆì•¡ (ì„ íƒ)
sort: ì •ë ¬ ê¸°ì¤€ (relevance|amount|deadline) (ê¸°ë³¸ê°’: relevance)
limit: ê²°ê³¼ ìˆ˜ ì œí•œ (ê¸°ë³¸ê°’: 20, ìµœëŒ€: 100)
offset: í˜ì´ì§€ë„¤ì´ì…˜ ì˜¤í”„ì…‹ (ê¸°ë³¸ê°’: 0)
```

**Response Example:**
```json
{
  "success": true,
  "data": {
    "policies": [
      {
        "policy_id": "uuid",
        "title": "ê²½ê¸°ë„ ì†Œìƒê³µì¸ íŠ¹ë³„ê²½ì˜ìê¸ˆ",
        "issuing_organization": "ê²½ê¸°ë„ì²­",
        "summary": "ê²½ê¸°ë„ ë‚´ ì†Œìƒê³µì¸ ê²½ì˜ ì•ˆì • ì§€ì›",
        "funding_details": {
          "max_amount": 50000000,
          "interest_rate": 2.5,
          "funding_type": "ëŒ€ì¶œ"
        },
        "application_period": {
          "start_date": "2025-01-01",
          "end_date": "2025-12-31"
        },
        "relevance_score": 0.95,
        "match_reasons": [
          "í‚¤ì›Œë“œ 'ì†Œìƒê³µì¸' ì •í™• ë§¤ì¹­",
          "ì§€ì—­ ì¡°ê±´ ì¼ì¹˜",
          "ì—…ì¢… ì¡°ê±´ ë¶€ë¶„ ì¼ì¹˜"
        ]
      }
    ],
    "pagination": {
      "total": 156,
      "limit": 20,
      "offset": 0,
      "has_next": true
    },
    "search_metadata": {
      "query_time_ms": 45,
      "total_searched": 3456,
      "search_strategy": "hybrid",
      "cache_hit": false
    }
  }
}
```

### 3.2. ìë™ì™„ì„± API
```http
GET /api/v1/search/autocomplete?q={partial_query}
```

**Response Example:**
```json
{
  "success": true,
  "data": {
    "suggestions": [
      {
        "text": "ì†Œìƒê³µì¸ ìš´ì˜ìê¸ˆ",
        "type": "keyword",
        "frequency": 1250
      },
      {
        "text": "ì†Œìƒê³µì¸ ì°½ì—…ìê¸ˆ",
        "type": "keyword", 
        "frequency": 890
      }
    ]
  }
}
```

## 4. ê²€ìƒ‰ ì—”ì§„ë³„ êµ¬í˜„

### 4.1. Elasticsearch ì„¤ì •
```json
{
  "settings": {
    "analysis": {
      "analyzer": {
        "korean_analyzer": {
          "type": "custom",
          "tokenizer": "nori_tokenizer",
          "filter": [
            "lowercase",
            "nori_part_of_speech",
            "nori_readingform",
            "stop"
          ]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "title": {
        "type": "text",
        "analyzer": "korean_analyzer",
        "fields": {
          "keyword": {
            "type": "keyword"
          }
        }
      },
      "content": {
        "type": "text",
        "analyzer": "korean_analyzer"
      },
      "issuing_organization": {
        "type": "keyword"
      },
      "target_regions": {
        "type": "keyword"
      },
      "target_industries": {
        "type": "keyword"
      },
      "funding_amount_max": {
        "type": "long"
      },
      "application_end_date": {
        "type": "date"
      }
    }
  }
}
```

### 4.2. ê²€ìƒ‰ ì¿¼ë¦¬ êµ¬í˜„
```python
class SearchService:
    def __init__(self):
        self.elasticsearch = Elasticsearch()
        self.milvus = MilvusClient()
        self.postgres = PostgreSQLClient()
        self.cache = RedisClient()
    
    async def hybrid_search(self, query: SearchQuery) -> SearchResult:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰"""
        # ìºì‹œ í™•ì¸
        cache_key = self.generate_cache_key(query)
        cached_result = await self.cache.get(cache_key)
        if cached_result:
            return cached_result
        
        # ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰
        tasks = [
            self.elasticsearch_search(query),
            self.vector_search(query),
            self.filter_search(query)
        ]
        
        es_results, vector_results, filter_results = await asyncio.gather(*tasks)
        
        # ê²°ê³¼ í†µí•© ë° ë­í‚¹
        merged_results = self.merge_results(es_results, vector_results, filter_results)
        ranked_results = self.rank_results(merged_results, query)
        
        # ìºì‹œ ì €ì¥
        await self.cache.setex(cache_key, 300, ranked_results)  # 5ë¶„ ìºì‹œ
        
        return ranked_results
    
    async def elasticsearch_search(self, query: SearchQuery) -> List[PolicyResult]:
        """Elasticsearch í‚¤ì›Œë“œ ê²€ìƒ‰"""
        search_body = {
            "query": {
                "bool": {
                    "must": [
                        {
                            "multi_match": {
                                "query": query.text,
                                "fields": ["title^3", "content^1", "summary^2"],
                                "type": "best_fields",
                                "fuzziness": "AUTO"
                            }
                        }
                    ],
                    "filter": self.build_filters(query)
                }
            },
            "highlight": {
                "fields": {
                    "title": {},
                    "content": {}
                }
            },
            "size": query.limit * 2  # ë” ë§ì€ í›„ë³´ í™•ë³´
        }
        
        response = await self.elasticsearch.search(
            index="aegis_policies",
            body=search_body
        )
        
        return self.parse_es_results(response)
    
    async def vector_search(self, query: SearchQuery) -> List[PolicyResult]:
        """Milvus ë²¡í„° ê²€ìƒ‰"""
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = await self.embedding_service.embed(query.text)
        
        # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰
        search_params = {
            "metric_type": "L2",
            "params": {"ef": 64}
        }
        
        results = await self.milvus.search(
            collection_name="aegis_policies_v1",
            data=[query_embedding],
            anns_field="embedding",
            param=search_params,
            limit=query.limit * 2,
            expr=self.build_milvus_filter(query)
        )
        
        return self.parse_vector_results(results)
    
    def merge_results(self, es_results: List, vector_results: List, 
                     filter_results: List) -> List[PolicyResult]:
        """ê²€ìƒ‰ ê²°ê³¼ í†µí•©"""
        result_map = {}
        
        # Elasticsearch ê²°ê³¼ (ê°€ì¤‘ì¹˜: 0.4)
        for result in es_results:
            policy_id = result.policy_id
            if policy_id not in result_map:
                result_map[policy_id] = result
                result_map[policy_id].scores = {}
            result_map[policy_id].scores['elasticsearch'] = result.score * 0.4
        
        # Vector ê²€ìƒ‰ ê²°ê³¼ (ê°€ì¤‘ì¹˜: 0.35)
        for result in vector_results:
            policy_id = result.policy_id
            if policy_id not in result_map:
                result_map[policy_id] = result
                result_map[policy_id].scores = {}
            result_map[policy_id].scores['vector'] = result.score * 0.35
        
        # Filter ê²€ìƒ‰ ê²°ê³¼ (ê°€ì¤‘ì¹˜: 0.25)
        for result in filter_results:
            policy_id = result.policy_id
            if policy_id not in result_map:
                result_map[policy_id] = result
                result_map[policy_id].scores = {}
            result_map[policy_id].scores['filter'] = result.score * 0.25
        
        # ìµœì¢… ì ìˆ˜ ê³„ì‚°
        for result in result_map.values():
            result.final_score = sum(result.scores.values())
        
        return list(result_map.values())
```

## 5. ì„±ëŠ¥ ìµœì í™”

### 5.1. ìºì‹± ì „ëµ
```python
class SearchCacheManager:
    def __init__(self):
        self.redis = RedisClient()
        self.cache_ttl = {
            'search_results': 300,      # 5ë¶„
            'autocomplete': 3600,       # 1ì‹œê°„
            'popular_queries': 86400,   # 24ì‹œê°„
        }
    
    def generate_cache_key(self, query: SearchQuery) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        key_parts = [
            query.text,
            query.region or '',
            query.industry or '',
            query.business_type or '',
            str(query.limit),
            str(query.offset),
            query.sort
        ]
        
        key_string = '|'.join(key_parts)
        return f"search:{hashlib.md5(key_string.encode()).hexdigest()}"
    
    async def get_cached_result(self, cache_key: str) -> Optional[SearchResult]:
        """ìºì‹œëœ ê²°ê³¼ ì¡°íšŒ"""
        cached_data = await self.redis.get(cache_key)
        if cached_data:
            return SearchResult.parse_raw(cached_data)
        return None
    
    async def cache_result(self, cache_key: str, result: SearchResult):
        """ê²€ìƒ‰ ê²°ê³¼ ìºì‹±"""
        await self.redis.setex(
            cache_key,
            self.cache_ttl['search_results'],
            result.json()
        )
```

### 5.2. ì¸ë±ìŠ¤ ìµœì í™”
```python
class IndexOptimizer:
    async def optimize_elasticsearch_index(self):
        """Elasticsearch ì¸ë±ìŠ¤ ìµœì í™”"""
        # ì¸ë±ìŠ¤ ì„¤ì • ìµœì í™”
        settings = {
            "refresh_interval": "30s",  # ì‹¤ì‹œê°„ì„± vs ì„±ëŠ¥ ê· í˜•
            "number_of_replicas": 1,
            "max_result_window": 10000
        }
        
        await self.elasticsearch.indices.put_settings(
            index="aegis_policies",
            body={"settings": settings}
        )
    
    async def optimize_milvus_index(self):
        """Milvus ì¸ë±ìŠ¤ ìµœì í™”"""
        index_params = {
            "metric_type": "L2",
            "index_type": "HNSW",
            "params": {
                "M": 16,
                "efConstruction": 64
            }
        }
        
        await self.milvus.create_index(
            collection_name="aegis_policies_v1",
            field_name="embedding",
            index_params=index_params
        )
```

---

**ğŸ“‹ ê´€ë ¨ ë¬¸ì„œ**
- [ì¶”ì²œ ì„œë¹„ìŠ¤](../RECOMMENDATION_SERVICE/01_RECOMMENDATION_SERVICE_OVERVIEW.md)
- [ì •ì±… ì„œë¹„ìŠ¤](../POLICY_SERVICE/01_POLICY_SERVICE_OVERVIEW.md)
- [API ëª…ì„¸ì„œ](../../03_DATA_AND_APIS/02_API_CONTRACT.md)