# ì´ì§€ìŠ¤(Aegis) ì„±ëŠ¥ ëª…ì„¸ì„œ

| í•­ëª© | ë‚´ìš© |
|------|------|
| ë¬¸ì„œ ID | AEG-QUA-20250917-2.0 |
| ë²„ì „ | 2.0 |
| ìµœì¢… ìˆ˜ì •ì¼ | 2025ë…„ 9ì›” 17ì¼ |
| ìƒíƒœ | í™•ì • (Finalized) |

## 1. ê°œìš” (Overview)

ë³¸ ë¬¸ì„œëŠ” ì´ì§€ìŠ¤ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ê³¼ ì¸¡ì • ê¸°ì¤€ì„ ì •ì˜í•œë‹¤. ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œì˜ ì‚¬ìš©ì ê²½í—˜ì„ ë³´ì¥í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì´ê³  ì¸¡ì • ê°€ëŠ¥í•œ ì„±ëŠ¥ ëª©í‘œë¥¼ ì œì‹œí•œë‹¤.

## 2. ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­ ê°œìš”

### 2.1. í•µì‹¬ ì„±ëŠ¥ ì§€í‘œ (KPI)
| ì§€í‘œ | ëª©í‘œê°’ | ì¸¡ì • ë°©ë²• |
|------|--------|-----------|
| **ì‘ë‹µ ì‹œê°„** | 95%ile < 3ì´ˆ | API ì‘ë‹µ ì‹œê°„ ì¸¡ì • |
| **ì²˜ë¦¬ëŸ‰** | 1,000 RPS | ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ëŠ¥ë ¥ |
| **ê°€ìš©ì„±** | 99.9% | ì›”ê°„ ë‹¤ìš´íƒ€ì„ < 43ë¶„ |
| **ë™ì‹œ ì‚¬ìš©ì** | 10,000ëª… | ë™ì‹œ ì ‘ì† ì²˜ë¦¬ ëŠ¥ë ¥ |

### 2.2. ì„±ëŠ¥ ì¸¡ì • í™˜ê²½
- **í•˜ë“œì›¨ì–´**: AWS EC2 c5.2xlarge (8 vCPU, 16GB RAM)
- **ë„¤íŠ¸ì›Œí¬**: 10Gbps ëŒ€ì—­í­
- **ë°ì´í„°ë² ì´ìŠ¤**: RDS PostgreSQL (db.r5.xlarge)
- **ìºì‹œ**: ElastiCache Redis (cache.r5.large)

## 3. API ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­

### 3.1. ì¶”ì²œ API ì„±ëŠ¥
**ì—”ë“œí¬ì¸íŠ¸**: `POST /api/v1/recommendations`

| ë©”íŠ¸ë¦­ | ëª©í‘œ | ì„ê³„ê°’ |
|--------|------|--------|
| í‰ê·  ì‘ë‹µì‹œê°„ | < 2ì´ˆ | < 3ì´ˆ |
| 95th percentile | < 3ì´ˆ | < 5ì´ˆ |
| 99th percentile | < 5ì´ˆ | < 8ì´ˆ |
| ì²˜ë¦¬ëŸ‰ | 500 RPS | 300 RPS |
| ì—ëŸ¬ìœ¨ | < 0.1% | < 1% |

**ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
```javascript
// K6 ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
export let options = {
  stages: [
    { duration: '5m', target: 100 },   // ì›Œë°ì—…
    { duration: '10m', target: 500 },  // ëª©í‘œ ë¶€í•˜
    { duration: '5m', target: 1000 },  // ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸
    { duration: '5m', target: 0 },     // ì¿¨ë‹¤ìš´
  ],
  thresholds: {
    http_req_duration: ['p(95)<3000'],
    http_req_failed: ['rate<0.001'],
  },
};
```

### 3.2. ê²€ìƒ‰ API ì„±ëŠ¥
**ì—”ë“œí¬ì¸íŠ¸**: `GET /api/v1/policies/search`

| ë©”íŠ¸ë¦­ | ëª©í‘œ | ì„ê³„ê°’ |
|--------|------|--------|
| í‰ê·  ì‘ë‹µì‹œê°„ | < 500ms | < 1ì´ˆ |
| 95th percentile | < 1ì´ˆ | < 2ì´ˆ |
| ì²˜ë¦¬ëŸ‰ | 2,000 RPS | 1,000 RPS |
| ìºì‹œ íˆíŠ¸ìœ¨ | > 80% | > 60% |

### 3.3. ì‚¬ìš©ì ê´€ë¦¬ API ì„±ëŠ¥
**ì—”ë“œí¬ì¸íŠ¸**: `GET /api/v1/users/profile`

| ë©”íŠ¸ë¦­ | ëª©í‘œ | ì„ê³„ê°’ |
|--------|------|--------|
| í‰ê·  ì‘ë‹µì‹œê°„ | < 200ms | < 500ms |
| 95th percentile | < 500ms | < 1ì´ˆ |
| ì²˜ë¦¬ëŸ‰ | 5,000 RPS | 2,000 RPS |

## 4. ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­

### 4.1. PostgreSQL ì„±ëŠ¥
| ë©”íŠ¸ë¦­ | ëª©í‘œ | ì„ê³„ê°’ |
|--------|------|--------|
| ì¿¼ë¦¬ ì‘ë‹µì‹œê°„ | < 100ms | < 500ms |
| ë™ì‹œ ì—°ê²° ìˆ˜ | 1,000ê°œ | 500ê°œ |
| CPU ì‚¬ìš©ë¥  | < 70% | < 85% |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  | < 80% | < 90% |
| ë””ìŠ¤í¬ I/O | < 80% | < 90% |

**ì£¼ìš” ì¿¼ë¦¬ ì„±ëŠ¥ ëª©í‘œ**:
```sql
-- ì •ì±… ê²€ìƒ‰ ì¿¼ë¦¬ (< 50ms)
SELECT * FROM policies 
WHERE is_active = true 
  AND target_regions && ARRAY['11'] 
  AND target_industries && ARRAY['56']
LIMIT 20;

-- ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ (< 10ms)
SELECT profile FROM users WHERE user_id = $1;

-- ì¶”ì²œ ì´ë ¥ ì¡°íšŒ (< 100ms)
SELECT * FROM recommendation_history 
WHERE user_id = $1 
ORDER BY created_at DESC 
LIMIT 10;
```

### 4.2. Milvus ë²¡í„° DB ì„±ëŠ¥
| ë©”íŠ¸ë¦­ | ëª©í‘œ | ì„ê³„ê°’ |
|--------|------|--------|
| ë²¡í„° ê²€ìƒ‰ ì‹œê°„ | < 50ms | < 100ms |
| ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œê°„ | < 10ë¶„ | < 30ë¶„ |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  | < 70% | < 85% |
| QPS | 1,000 | 500 |

**ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**:
```python
import time
from pymilvus import Collection

def test_vector_search_performance():
    collection = Collection("aegis_policies_v1")
    
    # ê²€ìƒ‰ ë²¡í„° ì¤€ë¹„
    search_vectors = [[0.1] * 768]  # 768ì°¨ì› ë²¡í„°
    
    start_time = time.time()
    
    # ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰
    results = collection.search(
        data=search_vectors,
        anns_field="embedding",
        param={"metric_type": "L2", "params": {"ef": 32}},
        limit=10
    )
    
    search_time = (time.time() - start_time) * 1000  # ms
    
    assert search_time < 50, f"Search time {search_time}ms exceeds 50ms"
    assert len(results[0]) == 10, "Should return 10 results"
```

### 4.3. Neo4j ê·¸ë˜í”„ DB ì„±ëŠ¥
| ë©”íŠ¸ë¦­ | ëª©í‘œ | ì„ê³„ê°’ |
|--------|------|--------|
| ê·¸ë˜í”„ ì¿¼ë¦¬ ì‹œê°„ | < 200ms | < 500ms |
| ë™ì‹œ ì¿¼ë¦¬ ìˆ˜ | 100ê°œ | 50ê°œ |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  | < 75% | < 90% |

**ê·¸ë˜í”„ ì¿¼ë¦¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**:
```cypher
// ì •ì±… ìê²© ìš”ê±´ í™•ì¸ ì¿¼ë¦¬ (< 200ms)
MATCH (p:Policy)-[:HAS_REQUIREMENT]->(r:Requirement)
WHERE p.id = $policy_id
RETURN p, collect(r) as requirements;

// ê´€ë ¨ ì •ì±… ì¶”ì²œ ì¿¼ë¦¬ (< 300ms)
MATCH (p1:Policy)-[:SIMILAR_TO]-(p2:Policy)
WHERE p1.id = $policy_id
RETURN p2
ORDER BY p2.relevance_score DESC
LIMIT 5;
```

## 5. ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­

### 5.1. CPU ì‚¬ìš©ë¥ 
| ì»´í¬ë„ŒíŠ¸ | í‰ìƒì‹œ | í”¼í¬ì‹œ | ì„ê³„ê°’ |
|----------|--------|--------|--------|
| API ì„œë²„ | < 50% | < 70% | < 85% |
| AI ì„œë¹„ìŠ¤ | < 60% | < 80% | < 90% |
| ë°ì´í„°ë² ì´ìŠ¤ | < 40% | < 70% | < 85% |
| ìºì‹œ ì„œë²„ | < 30% | < 50% | < 70% |

### 5.2. ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
| ì»´í¬ë„ŒíŠ¸ | í‰ìƒì‹œ | í”¼í¬ì‹œ | ì„ê³„ê°’ |
|----------|--------|--------|--------|
| API ì„œë²„ | < 60% | < 80% | < 90% |
| AI ì„œë¹„ìŠ¤ | < 70% | < 85% | < 95% |
| ë°ì´í„°ë² ì´ìŠ¤ | < 70% | < 85% | < 90% |
| ìºì‹œ ì„œë²„ | < 80% | < 90% | < 95% |

### 5.3. ë„¤íŠ¸ì›Œí¬ ì„±ëŠ¥
| ë©”íŠ¸ë¦­ | ëª©í‘œ | ì„ê³„ê°’ |
|--------|------|--------|
| ëŒ€ì—­í­ ì‚¬ìš©ë¥  | < 60% | < 80% |
| íŒ¨í‚· ì†ì‹¤ë¥  | < 0.01% | < 0.1% |
| ë„¤íŠ¸ì›Œí¬ ì§€ì—°ì‹œê°„ | < 10ms | < 50ms |

## 6. í™•ì¥ì„± ìš”êµ¬ì‚¬í•­

### 6.1. ìˆ˜í‰ í™•ì¥ (Horizontal Scaling)
**ëª©í‘œ**: íŠ¸ë˜í”½ ì¦ê°€ ì‹œ ìë™ ìŠ¤ì¼€ì¼ë§

```yaml
# Kubernetes HPA ì„¤ì •
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: aegis-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: aegis-api
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### 6.2. ìˆ˜ì§ í™•ì¥ (Vertical Scaling)
**ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤ì¼€ì¼ë§ ê³„íš**:

| ì‚¬ìš©ì ìˆ˜ | ì¸ìŠ¤í„´ìŠ¤ íƒ€ì… | vCPU | ë©”ëª¨ë¦¬ | ìŠ¤í† ë¦¬ì§€ |
|-----------|---------------|------|--------|----------|
| < 10K | db.r5.large | 2 | 16GB | 100GB |
| 10K-50K | db.r5.xlarge | 4 | 32GB | 500GB |
| 50K-100K | db.r5.2xlarge | 8 | 64GB | 1TB |
| > 100K | db.r5.4xlarge | 16 | 128GB | 2TB |

## 7. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼

### 7.1. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­
```python
from prometheus_client import Counter, Histogram, Gauge

# API ì„±ëŠ¥ ë©”íŠ¸ë¦­
api_request_duration = Histogram(
    'api_request_duration_seconds',
    'API request duration',
    ['method', 'endpoint', 'status']
)

api_requests_total = Counter(
    'api_requests_total',
    'Total API requests',
    ['method', 'endpoint', 'status']
)

# ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ë©”íŠ¸ë¦­
cpu_usage = Gauge('cpu_usage_percent', 'CPU usage percentage')
memory_usage = Gauge('memory_usage_percent', 'Memory usage percentage')
disk_usage = Gauge('disk_usage_percent', 'Disk usage percentage')

# ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ë©”íŠ¸ë¦­
db_query_duration = Histogram(
    'db_query_duration_seconds',
    'Database query duration',
    ['query_type']
)

db_connections_active = Gauge(
    'db_connections_active',
    'Active database connections'
)
```

### 7.2. ì„±ëŠ¥ ì•Œë¦¼ ê·œì¹™
```yaml
# Prometheus ì•Œë¦¼ ê·œì¹™
groups:
- name: performance_alerts
  rules:
  - alert: HighAPILatency
    expr: histogram_quantile(0.95, api_request_duration_seconds) > 3
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "API latency is high"
      description: "95th percentile latency is {{ $value }}s"

  - alert: HighCPUUsage
    expr: cpu_usage_percent > 85
    for: 10m
    labels:
      severity: critical
    annotations:
      summary: "High CPU usage detected"
      description: "CPU usage is {{ $value }}%"

  - alert: DatabaseSlowQuery
    expr: histogram_quantile(0.95, db_query_duration_seconds) > 0.5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "Database queries are slow"
      description: "95th percentile query time is {{ $value }}s"
```

## 8. ì„±ëŠ¥ ìµœì í™” ì „ëµ

### 8.1. ìºì‹± ì „ëµ
**ë‹¤ì¸µ ìºì‹± êµ¬ì¡°**:
```python
class PerformanceOptimizedService:
    def __init__(self):
        self.l1_cache = {}  # ì• í”Œë¦¬ì¼€ì´ì…˜ ë©”ëª¨ë¦¬ ìºì‹œ
        self.l2_cache = redis.Redis()  # Redis ìºì‹œ
        self.l3_cache = None  # CDN ìºì‹œ
    
    async def get_policy_with_cache(self, policy_id: str):
        # L1 ìºì‹œ í™•ì¸
        if policy_id in self.l1_cache:
            return self.l1_cache[policy_id]
        
        # L2 ìºì‹œ í™•ì¸
        cached_data = await self.l2_cache.get(f"policy:{policy_id}")
        if cached_data:
            policy = json.loads(cached_data)
            self.l1_cache[policy_id] = policy  # L1ì— ì €ì¥
            return policy
        
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì¡°íšŒ
        policy = await self.db.get_policy(policy_id)
        
        # ìºì‹œì— ì €ì¥
        await self.l2_cache.setex(
            f"policy:{policy_id}", 
            3600, 
            json.dumps(policy)
        )
        self.l1_cache[policy_id] = policy
        
        return policy
```

### 8.2. ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”
**ì¸ë±ìŠ¤ ìµœì í™”**:
```sql
-- ë³µí•© ì¸ë±ìŠ¤ë¡œ ì¿¼ë¦¬ ì„±ëŠ¥ í–¥ìƒ
CREATE INDEX CONCURRENTLY idx_policies_search 
ON policies (is_active, target_regions, target_industries) 
WHERE is_active = true;

-- ë¶€ë¶„ ì¸ë±ìŠ¤ë¡œ ì¸ë±ìŠ¤ í¬ê¸° ìµœì í™”
CREATE INDEX CONCURRENTLY idx_policies_recent 
ON policies (created_at) 
WHERE created_at > NOW() - INTERVAL '1 year';

-- í•¨ìˆ˜ ê¸°ë°˜ ì¸ë±ìŠ¤
CREATE INDEX CONCURRENTLY idx_policies_text_search 
ON policies USING GIN (to_tsvector('korean', title || ' ' || content));
```

### 8.3. ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncOptimizedService:
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=10)
    
    async def get_recommendations_optimized(self, query: str, user_profile: dict):
        # ë³‘ë ¬ë¡œ ì—¬ëŸ¬ ì‘ì—… ì‹¤í–‰
        tasks = [
            self.vector_search(query),
            self.knowledge_graph_query(user_profile),
            self.business_rules_evaluation(user_profile)
        ]
        
        # ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        vector_results, kg_results, rules_results = await asyncio.gather(*tasks)
        
        # ê²°ê³¼ í†µí•©
        return self.combine_results(vector_results, kg_results, rules_results)
    
    async def vector_search(self, query: str):
        # CPU ì§‘ì•½ì  ì‘ì—…ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(
            self.executor, 
            self._cpu_intensive_vector_search, 
            query
        )
```

## 9. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ìë™í™”

### 9.1. ì§€ì†ì  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
```yaml
# GitHub Actions ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
name: Performance Tests

on:
  schedule:
    - cron: '0 2 * * *'  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ
  push:
    branches: [ main ]

jobs:
  performance-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      
      - name: Setup test environment
        run: |
          docker-compose -f docker-compose.perf.yml up -d
          sleep 60  # ì„œë¹„ìŠ¤ ì‹œì‘ ëŒ€ê¸°
      
      - name: Run load tests
        run: |
          docker run --rm -v $PWD:/app grafana/k6 run /app/tests/performance/load-test.js
      
      - name: Run stress tests
        run: |
          docker run --rm -v $PWD:/app grafana/k6 run /app/tests/performance/stress-test.js
      
      - name: Generate performance report
        run: |
          python scripts/generate_perf_report.py
      
      - name: Upload results
        uses: actions/upload-artifact@v3
        with:
          name: performance-results
          path: performance-report.html
```

### 9.2. ì„±ëŠ¥ íšŒê·€ í…ŒìŠ¤íŠ¸
```python
class PerformanceRegressionTest:
    def __init__(self):
        self.baseline_metrics = self.load_baseline_metrics()
    
    def test_api_performance_regression(self):
        current_metrics = self.run_performance_test()
        
        for endpoint, current_latency in current_metrics.items():
            baseline_latency = self.baseline_metrics.get(endpoint)
            
            if baseline_latency:
                # 10% ì´ìƒ ì„±ëŠ¥ ì €í•˜ ì‹œ ì‹¤íŒ¨
                regression_threshold = baseline_latency * 1.1
                
                assert current_latency <= regression_threshold, \
                    f"Performance regression detected for {endpoint}: " \
                    f"current={current_latency}ms, baseline={baseline_latency}ms"
    
    def update_baseline_if_improved(self, current_metrics):
        """ì„±ëŠ¥ì´ ê°œì„ ëœ ê²½ìš° ë² ì´ìŠ¤ë¼ì¸ ì—…ë°ì´íŠ¸"""
        for endpoint, current_latency in current_metrics.items():
            baseline_latency = self.baseline_metrics.get(endpoint)
            
            if baseline_latency and current_latency < baseline_latency * 0.9:
                # 10% ì´ìƒ ê°œì„ ëœ ê²½ìš° ë² ì´ìŠ¤ë¼ì¸ ì—…ë°ì´íŠ¸
                self.baseline_metrics[endpoint] = current_latency
        
        self.save_baseline_metrics()
```

---

**ğŸ“‹ ê´€ë ¨ ë¬¸ì„œ**
- [í…ŒìŠ¤íŠ¸ ì „ëµ](./01_TESTING_STRATEGY.md)
- [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](../01_ARCHITECTURE/01_SYSTEM_OVERVIEW.md)
- [ëª¨ë‹ˆí„°ë§ ë° ê´€ì°°ê°€ëŠ¥ì„±](../05_OPERATIONS/03_MONITORING_AND_OBSERVABILITY.md)